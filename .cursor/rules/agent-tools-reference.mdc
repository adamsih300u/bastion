# Agent Tools Reference

## Tool Architecture Overview

**BULLY!** Agents have access to two types of tools:

1. **Backend gRPC Tools** (`orchestrator/tools/`) - Require backend services via gRPC
2. **Pure Utility Functions** (`orchestrator/utils/`) - Stateless functions, no backend needed

## Tool Location Guidelines

### When to Use `orchestrator/tools/`
- Tools that call backend services via gRPC
- Tools that need database access
- Tools that require user authentication
- Tools that interact with external APIs

**Pattern**: Import from `orchestrator.tools.*` modules

### When to Use `orchestrator/utils/`
- Pure Python functions with no side effects
- String manipulation utilities
- Content generation helpers
- Filename/title/description generators
- Stateless transformation functions

**Pattern**: Import from `orchestrator.utils.*` modules

## Available Tools by Category

### Document Tools (`orchestrator/tools/document_tools.py`)
**Backend gRPC tools for document operations**

- `search_documents_structured(query, user_id, limit)` - Semantic vector search
- `get_document_content_tool(document_id, user_id)` - Get full document content
- `search_by_tags_tool(tags, user_id, limit)` - Search by document tags
- `search_within_document_tool(document_id, query, search_type, context_window, user_id)` - Search for terms within a specific document

**Usage**:
```python
from orchestrator.tools.document_tools import search_documents_structured, get_document_content_tool

results = await search_documents_structured(query="circuit design", user_id=user_id, limit=20)
content = await get_document_content_tool(document_id, user_id)
```

### Segment Search Tools (`orchestrator/tools/segment_search_tools.py`)
**Universal tools for finding relevant SEGMENTS within documents**

These tools search for specific sections/segments within documents, not just documents themselves. This enables precise updates to specific sections and prioritizes project documents over library documents.

- `search_segments_across_documents_tool(queries, project_documents, user_id, ...)` - Search for relevant segments across multiple documents
- `extract_relevant_content_section(full_content, query, max_length, domain_keywords)` - Extract relevant sections from document content

**Key Features:**
- **Prioritizes project documents**: Searches project files first, then library documents
- **Returns segments, not documents**: Provides specific sections with context
- **Structured segment data**: Includes section names, positions, and relevance scores
- **Domain-agnostic**: Works for any domain (electronics, fiction, research, etc.)

**Usage**:
```python
from orchestrator.tools.segment_search_tools import search_segments_across_documents_tool

# Project documents from referenced_context
project_docs = {
    "components": [
        {"document_id": "doc1", "filename": "component_spec.md"},
        {"document_id": "doc2", "filename": "circuit_design.md"}
    ]
}

# Search queries (can be from generate_project_aware_queries or simple strings)
queries = [
    "ESP32 keyboard matrix scanning",
    "keyboard scanning circuit design"
]

# Perform segment search
result = await search_segments_across_documents_tool(
    queries=queries,
    project_documents=project_docs,
    user_id=user_id,
    limit_per_query=5,
    max_queries=3,
    prioritize_project_docs=True,
    context_window=500,
    domain_keywords=["circuit", "schematic", "voltage"]  # Optional domain-specific keywords
)

# Access results
segments = result["segments"]
for segment in segments:
    print(f"Found in {segment['filename']}: {segment['section_name']}")
    print(f"Content: {segment['content'][:200]}...")
    print(f"Source: {segment['source']}")  # "project_document" or "library_document"
    print(f"Relevance: {segment['relevance_score']}")

# Result structure:
# {
#     "segments": [
#         {
#             "document_id": "...",
#             "filename": "...",
#             "section_name": "...",
#             "content": "...",
#             "section_start": 123,
#             "section_end": 456,
#             "match_start": 200,  # Only for project docs
#             "match_end": 250,     # Only for project docs
#             "source": "project_document" | "library_document",
#             "relevance_score": 0.85,
#             "search_query": "..."
#         }
#     ],
#     "documents_found_count": 5,
#     "project_doc_count": 3,
#     "library_doc_count": 2
# }
```

**Use Cases:**
- **Electronics Agent**: Finding specific component sections that need updates
- **Fiction Editing Agent**: Finding specific scenes/chapters across project files
- **Content Analysis Agent**: Finding relevant segments across multiple documents
- **Research Agent**: Searching project files + library for comprehensive results
- **Any Project-Based Agent**: Finding precise sections within project documentation

**Benefits:**
- Enables precise, targeted updates to specific sections
- Prioritizes project context (most relevant)
- Returns structured segment data for routing
- Reusable across all project-based agents

### Information Analysis Tools (`orchestrator/tools/information_analysis_tools.py`)
**LLM-powered tools for understanding information needs and generating targeted queries**

These tools help agents understand what information is needed and generate project-aware search queries.

- `analyze_information_needs_tool(query, query_type, project_context, ...)` - Analyze what information is needed
- `generate_project_aware_queries_tool(query, query_type, information_needs, project_context, ...)` - Generate targeted queries

**Key Features:**
- **Domain-agnostic**: Works for any domain (electronics, fiction, research, etc.)
- **Project context aware**: Uses project context to identify relevant entities
- **Gap analysis**: Identifies information gaps before searching
- **Targeted queries**: Generates queries optimized for project context

**Usage**:
```python
from orchestrator.tools.information_analysis_tools import (
    analyze_information_needs_tool,
    generate_project_aware_queries_tool
)

# Step 1: Analyze information needs
project_context = {
    "components": ["ESP32", "keyboard matrix"],
    "protocols": ["I2C", "SPI"],
    "characters": ["protagonist", "antagonist"],  # For fiction
    "plot_points": ["act 1", "climax"]  # For fiction
}

# Get LLM function from agent (agents should pass their _get_llm method)
get_llm_func = lambda: self._get_llm(temperature=0.1, model=fast_model, state=state)

information_needs = await analyze_information_needs_tool(
    query="How to implement keyboard scanning",
    query_type="circuit_design",
    project_context=project_context,
    context_keys=["components", "protocols"],
    domain_name="electronics",
    user_id=user_id,
    get_llm_func=get_llm_func
)

# Step 2: Generate project-aware queries
result = await generate_project_aware_queries_tool(
    query="keyboard scanning",
    query_type="circuit_design",
    information_needs=information_needs,
    project_context=project_context,
    domain_examples=[
        "ESP32 keyboard matrix scanning circuit design",
        "I2C sensor communication protocol implementation"
    ],
    user_id=user_id,
    num_queries=5,
    get_llm_func=lambda: self._get_llm(temperature=0.2, model=fast_model, state=state)
)

queries = result["search_queries"]
# [
#   {"query": "ESP32 keyboard matrix scanning", "priority": 1, "focus": "Project-specific implementation"},
#   {"query": "keyboard scanning circuit design I2C", "priority": 2, "focus": "Protocol integration"}
# ]
```

**Relationship to Query Expansion:**
- **Query Expansion** (`expand_query_tool`): Creates semantic variations of a query
- **Project-Aware Generation**: Creates context-specific, targeted queries
- **Can be used together**: Expand first, then make project-aware, or use independently

**Use Cases:**
- **Electronics Agent**: Identify component/protocol gaps, generate targeted queries
- **Fiction Editing Agent**: Identify story element gaps, generate character/plot queries
- **Research Agent**: Identify research gaps, generate targeted research queries
- **Content Analysis Agent**: Identify analysis needs, generate targeted analysis queries
- **Any Project-Based Agent**: Understand information needs and generate targeted searches

**Benefits:**
- Helps agents understand what they need before searching
- Enables targeted, efficient searches
- Leverages project context for better results
- Reusable across domains with appropriate context extraction

### Document Editing Tools (`orchestrator/tools/document_editing_tools.py`)
**Backend gRPC tools for document editing and proposals**

- `update_document_metadata_tool(document_id, title, frontmatter_type, user_id)` - Update document metadata
- `update_document_content_tool(document_id, content, user_id, append)` - Update document content
- `propose_document_edit_tool(document_id, edit_type, operations, content_edit, agent_name, summary, requires_preview, user_id)` - Propose edits for user review
- `apply_operations_directly_tool(document_id, operations, user_id, agent_name)` - Restricted! Apply operations directly to a file (bypass proposal)
- `apply_document_edit_proposal_tool(proposal_id, selected_operation_indices, user_id)` - Apply an approved edit proposal

**Usage**:
```python
from orchestrator.tools.document_editing_tools import (
    update_document_content_tool,
    propose_document_edit_tool
)

await update_document_content_tool(document_id, content, user_id, append=True)
await propose_document_edit_tool(
    document_id=doc_id,
    edit_type="operations",
    operations=[...],
    agent_name="electronics_agent",
    summary="Update component specifications",
    user_id=user_id
)
```

### File Creation Tools (`orchestrator/tools/file_creation_tools.py`)
**Backend gRPC tools for file/folder creation**

- `create_user_file_tool(filename, content, folder_path, title, tags, category, user_id)` - Create user document
- `create_user_folder_tool(folder_name, parent_folder_path, user_id)` - Create user folder

**Usage**:
```python
from orchestrator.tools.file_creation_tools import create_user_file_tool, create_user_folder_tool

result = await create_user_file_tool(
    filename="component_spec.md",
    content="# Component Spec\n\n...",
    folder_path="Projects/Electronics",
    title="Component Specification",
    tags=["electronics", "component"],
    category="electronics",
    user_id=user_id
)
```

### Math Tools (`orchestrator/tools/math_tools.py`, `orchestrator/tools/math_formulas.py`, `orchestrator/tools/unit_conversions.py`)
**Deterministic mathematical calculations, formula execution, and unit conversions**

- `calculate_expression_tool(expression, variables)` - Safely evaluate mathematical expressions
- `evaluate_formula_tool(formula_name, inputs)` - Evaluate pre-defined formulas (HVAC, electrical, construction)
- `convert_units_tool(value, from_unit, to_unit, quantity_type)` - Convert between different units
- `list_available_formulas_tool()` - List all formulas in the library

**Available Formulas**:
- `manual_j_heat_loss` - ACCA Manual J heat loss calculation (see detailed documentation below)
- `btu_hvac` - Simple BTU calculation for HVAC sizing
- `ohms_law_voltage`, `ohms_law_current`, `ohms_law_resistance` - Electrical calculations
- `power_dissipation` - Power calculation
- `voltage_divider` - Resistor voltage divider
- `capacitor_impedance` - Capacitor reactance
- `area_rectangle`, `volume_rectangular` - Geometry calculations
- `material_quantity` - Material estimation

**Usage**:
```python
from orchestrator.tools.math_tools import calculate_expression_tool
from orchestrator.tools.math_formulas import evaluate_formula_tool
from orchestrator.tools.unit_conversions import convert_units_tool

# Simple calculation
calc = await calculate_expression_tool("300 * 25 * 1.2")

# HVAC BTU calculation
btu = await evaluate_formula_tool("btu_hvac", {"square_feet": 300, "climate_factor": 1.2})

# Manual J heat loss calculation
heat_loss = await evaluate_formula_tool(
    formula_name="manual_j_heat_loss",
    inputs={
        "outdoor_design_temp": 10,
        "indoor_design_temp": 70,
        "floor_area": 2000,
        "wall_area": 1200,
        "wall_r_value": 19.0,
        "roof_r_value": 38.0,
        "window_area": 200,
        "window_u_value": 0.35,
        "air_changes_per_hour": 0.3,
        "occupant_count": 4
    }
)

# Unit conversion
meters = await convert_units_tool(300, "sq_ft", "sq_m", "area")
```

**Manual J Heat Loss Calculation (`manual_j_heat_loss` formula)**:

Performs comprehensive heat loss calculation according to ACCA Manual J methodology for residential HVAC sizing.

**Required Inputs**:
- `outdoor_design_temp` (float): Outdoor design temperature (Â°F) - typically 99% heating dry bulb for location
- `indoor_design_temp` (float): Indoor design temperature (Â°F) - typically 70Â°F for heating
- `floor_area` (float): Total conditioned floor area (sq ft)

**Optional Inputs** (with defaults):
- `ceiling_height` (float): Ceiling height in feet (default: 8.0)
- **Wall Construction**:
  - `wall_area` (float): Total wall area in sq ft (default: 0.0 - not included if 0)
  - `wall_r_value` (float): Wall R-value (default: 13.0)
- **Roof/Ceiling Construction**:
  - `roof_area` (float): Roof/ceiling area in sq ft (default: uses floor_area if not specified)
  - `roof_r_value` (float): Roof/ceiling R-value (default: 30.0)
- **Floor Construction**:
  - `floor_r_value` (float): Floor R-value (default: 19.0)
  - `floor_over_unconditioned` (bool): True if floor over unconditioned space (default: False)
- **Windows**:
  - `window_area` (float): Total window area in sq ft (default: 0.0)
  - `window_u_value` (float): Window U-value (default: 0.5 - double pane)
- **Doors**:
  - `door_area` (float): Total door area in sq ft (default: 0.0)
  - `door_u_value` (float): Door U-value (default: 0.2 - insulated door)
- **Infiltration**:
  - `air_changes_per_hour` (float): ACH from air leakage (default: 0.5 - tight construction)
- **Ventilation**:
  - `ventilation_cfm` (float): Mechanical ventilation CFM (default: 0.0)
- **Internal Heat Gains** (subtracted from losses):
  - `occupant_count` (int): Number of occupants (default: 0)
  - `appliance_heat_gain` (float): Heat gain from appliances in BTU/hr (default: 0.0)
  - `lighting_heat_gain` (float): Heat gain from lighting in BTU/hr (default: 0.0)

**Calculation Methodology**:
1. **Conduction Losses**: Q = U Ã— A Ã— Î”T through walls, roof, floor, windows, doors
   - U-value = 1/R-value (thermal transmittance)
   - Î”T = indoor_design_temp - outdoor_design_temp
2. **Infiltration Losses**: Q = 0.018 Ã— V Ã— ACH Ã— Î”T
   - V = building volume (floor_area Ã— ceiling_height)
   - ACH = air changes per hour
3. **Ventilation Losses**: Q = 1.08 Ã— CFM Ã— Î”T
   - CFM = mechanical ventilation rate
4. **Internal Heat Gains**: 
   - Occupants: 400 BTU/hr per person
   - Appliances and lighting: user-specified
5. **Net Heat Loss**: Total losses minus internal gains

**Returns**: Dictionary with:
- `result`: Net heat loss in BTU/hr
- `unit`: "BTU/hr"
- `formula_used`: "manual_j_heat_loss"
- `steps`: Detailed calculation steps showing all components (conduction, infiltration, ventilation, gains)
- `inputs_used`: All inputs used in calculation
- `success`: Boolean

**Example**:
```python
result = await evaluate_formula_tool(
    formula_name="manual_j_heat_loss",
    inputs={
        "outdoor_design_temp": 10,  # 99% design temp for location
        "indoor_design_temp": 70,
        "floor_area": 2000,
        "ceiling_height": 9.0,
        "wall_area": 1200,
        "wall_r_value": 19.0,  # R-19 walls
        "roof_r_value": 38.0,  # R-38 roof
        "window_area": 200,
        "window_u_value": 0.35,  # Low-E windows
        "door_area": 40,
        "door_u_value": 0.2,
        "air_changes_per_hour": 0.3,  # Very tight construction
        "occupant_count": 4,
        "appliance_heat_gain": 500
    }
)

# Result includes detailed breakdown in steps:
# - Conduction losses by component (walls, roof, floor, windows, doors)
# - Infiltration and ventilation losses
# - Internal gains (occupants, appliances, lighting)
# - Net heat loss (total losses minus gains)
```

### File Analysis Tools (`orchestrator/tools/file_analysis_tools.py`)
**Deterministic text analysis for precise word counts, character counts, and other text metrics**

These tools provide accurate, consistent text measurements using pure Python algorithms (no LLM estimation).

- `analyze_text_metrics(text, include_advanced, user_id)` - Analyze raw text content and return comprehensive metrics
- `analyze_document_metrics(document_id, user_id, include_advanced)` - Analyze document by document_id and return metrics
- `analyze_active_editor_metrics(active_editor, include_advanced, user_id)` - Analyze active editor content and return metrics

**Available Metrics:**
- `word_count`: Number of words (using word boundary detection)
- `line_count`: Total lines (including empty lines)
- `non_empty_line_count`: Lines with actual content
- `character_count`: Total characters (including spaces)
- `character_count_no_spaces`: Characters excluding spaces
- `paragraph_count`: Number of paragraphs
- `sentence_count`: Number of sentences
- `avg_words_per_sentence`: Average words per sentence (if `include_advanced=True`)
- `avg_words_per_paragraph`: Average words per paragraph (if `include_advanced=True`)

**Usage**:
```python
from orchestrator.tools.file_analysis_tools import (
    analyze_text_metrics,
    analyze_document_metrics,
    analyze_active_editor_metrics
)

# Analyze raw text
metrics = await analyze_text_metrics(
    text="Your text content here...",
    include_advanced=True,
    user_id=user_id
)
print(f"Word count: {metrics['word_count']:,}")
print(f"Sentences: {metrics['sentence_count']:,}")

# Analyze document by ID
metrics = await analyze_document_metrics(
    document_id=doc_id,
    user_id=user_id,
    include_advanced=True
)

# Analyze active editor content
metrics = await analyze_active_editor_metrics(
    active_editor=active_editor,
    include_advanced=True,
    user_id=user_id
)
```

**Use Cases:**
- **Story Analysis Agent**: Get precise word counts, chapter lengths, pacing metrics
- **Content Analysis**: Measure document statistics for quality assessment
- **Writing Metrics**: Track word counts, sentence/paragraph averages
- **Comparative Analysis**: Compare metrics between different sections or documents

**Key Features:**
- âœ… **Deterministic**: Same text always produces same metrics
- âœ… **Precise**: Uses regex word boundary detection (consistent with prose_quality.py)
- âœ… **Fast**: Pure Python implementation, no external dependencies
- âœ… **Comprehensive**: Basic metrics + optional advanced metrics (averages)

### Web Tools (`orchestrator/tools/web_tools.py`)
**Backend gRPC tools for web search**

- `search_web_tool(query, num_results)` - Standard web search
- `search_web_structured(query, num_results)` - Structured web search with snippets
- `crawl_web_content_tool(url)` - Crawl web content and extract text
- `search_and_crawl_tool(query, num_results)` - Combined search and crawl for better context

**Usage**:
```python
from orchestrator.tools.web_tools import search_web_structured, crawl_web_content_tool

results = await search_web_structured(query="Arduino ESP32 tutorial", num_results=10)
content = await crawl_web_content_tool(url="https://example.com/guide")
```

### Weather Tools (`backend/services/langgraph_tools/weather_tools.py`)
**Backend tools for retrieving current, forecast, and historical weather data**

- `weather_conditions(location, units, user_id)` - Get current weather conditions
- `weather_forecast(location, days, units, user_id)` - Get weather forecast (up to 5 days)
- `weather_history(location, date_str, units, user_id)` - Get historical weather data

**Key Features:**
- **Automatic location fallback**: If `user_id` is provided and location is vague (e.g., "user's location", "my location", empty string), the system automatically retrieves the user's ZIP code from their profile settings and uses it for geocoding
- **Date range support**: Historical weather supports multiple date formats:
  - `"YYYY-MM-DD"` - Specific day (e.g., `"2022-12-15"`)
  - `"YYYY-MM"` - Monthly average (e.g., `"2022-12"`)
  - `"YYYY-MM to YYYY-MM"` or `"YYYY-MM - YYYY-MM"` - Date range (e.g., `"2022-10 to 2024-02"`)
    - Expands into monthly queries for each month in the range
    - Returns aggregated averages across the entire range
    - Maximum range: 24 months (2 years) to prevent excessive API calls

**Usage**:
```python
from services.langgraph_tools.weather_tools import (
    weather_conditions,
    weather_forecast,
    weather_history
)

# Current weather
result = await weather_conditions(
    location="Los Angeles, CA",
    units="imperial",
    user_id=user_id
)

# Automatic fallback to user's ZIP code
result = await weather_conditions(
    location="user's location",  # Will use user's ZIP from profile
    units="imperial",
    user_id=user_id
)

# Weather forecast
result = await weather_forecast(
    location="New York, NY",
    days=5,
    units="imperial",
    user_id=user_id
)

# Historical weather - specific day
result = await weather_history(
    location="14532",
    date_str="2022-12-15",
    units="imperial",
    user_id=user_id
)

# Historical weather - monthly average
result = await weather_history(
    location="90210",
    date_str="2022-12",
    units="imperial",
    user_id=user_id
)

# Historical weather - date range (expands into monthly queries)
result = await weather_history(
    location="14532",
    date_str="2022-10 to 2024-02",
    units="imperial",
    user_id=user_id
)
```

**Return Formats:**
- **Current weather**: Temperature, conditions, humidity, wind speed, moon phase
- **Forecast**: Multi-day forecast with daily conditions
- **Historical (daily)**: Temperature, conditions, humidity, wind speed, pressure for specific day
- **Historical (monthly)**: Average, min, max temperatures, average humidity, average wind speed, most common conditions
- **Historical (date range)**: Aggregated data across all months including `monthly_data` array with per-month averages

**Location Fallback Behavior:**
When `user_id` is provided and location is one of these vague values:
- `"user's location"`, `"my location"`, `"current location"`, `""`, `"none"`, `"unknown"`

The system will:
1. Retrieve the user's ZIP code from their profile settings
2. Use that ZIP code for geocoding
3. Log the resolution: `"ðŸ“ Resolving vague location 'user's location' to user's ZIP: 14532"`

If no ZIP code is found in the user's profile, the system will log a warning and attempt to geocode the original vague location (which will likely fail).

**Note**: Requires OpenWeatherMap One Call API 3.0 subscription for historical data access

### Visualization Tools (`orchestrator/tools/visualization_tools.py`)
**Pure utility tools for generating charts and graphs from structured data**

- `create_chart_tool(chart_type, data, title, x_label, y_label, interactive, color_scheme, width, height)` - Generate charts and graphs

**Key Features:**
- **Comprehensive chart types**: bar, line, pie, scatter, area, heatmap, box_plot, histogram
- **Interactive and static output**: Generate interactive HTML charts or base64-encoded PNG images
- **Flexible data formats**: Supports single and multiple series data
- **Professional appearance**: Uses Plotly for polished, modern charts

**Chart Types and Data Formats:**

**Bar Chart:**
```python
data = {
    "labels": ["Q1", "Q2", "Q3", "Q4"],
    "values": [100, 150, 120, 180],
    "series_name": "Sales",  # optional
    "orientation": "v"  # "v" for vertical, "h" for horizontal
}
```

**Line Chart (single series):**
```python
data = {
    "x": [1, 2, 3, 4, 5],
    "y": [10, 15, 13, 17, 20],
    "series_name": "Temperature"
}
```

**Line Chart (multiple series):**
```python
data = {
    "series": [
        {"x": [1, 2, 3], "y": [10, 15, 13], "name": "Series A"},
        {"x": [1, 2, 3], "y": [8, 12, 11], "name": "Series B"}
    ]
}
```

**Pie Chart:**
```python
data = {
    "labels": ["Chrome", "Firefox", "Safari", "Edge"],
    "values": [45, 25, 20, 10]
}
```

**Scatter Plot:**
```python
data = {
    "x": [1, 2, 3, 4, 5],
    "y": [2, 4, 3, 5, 6],
    "series_name": "Data Points"
}
```

**Area Chart:**
```python
data = {
    "x": [1, 2, 3, 4, 5],
    "y": [10, 12, 11, 15, 14],
    "series_name": "Revenue"
}
```

**Heatmap:**
```python
data = {
    "z": [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
    "x_labels": ["A", "B", "C"],  # optional
    "y_labels": ["Row 1", "Row 2", "Row 3"]  # optional
}
```

**Box Plot:**
```python
data = {
    "values": [10, 12, 11, 15, 14, 13, 16, 12, 14, 15],  # Single group
    # OR multiple groups:
    "labels": ["Group A", "Group B"],
    "values": [[10, 12, 11], [15, 14, 13]]
}
```

**Histogram:**
```python
data = {
    "values": [10, 12, 11, 15, 14, 13, 16, 12, 14, 15],
    "bins": 10  # optional
}
```

**Usage**:
```python
from orchestrator.tools.visualization_tools import create_chart_tool

# Bar chart comparing sales
result = await create_chart_tool(
    chart_type="bar",
    data={"labels": ["Q1", "Q2", "Q3"], "values": [100, 150, 120]},
    title="Quarterly Sales",
    y_label="Revenue ($)",
    interactive=True,
    width=800,
    height=600
)

if result["success"]:
    if result["output_format"] == "base64_png":
        # Embed as markdown image
        chart_markdown = f"![Chart]({result['chart_data']})"
    else:  # HTML
        # Embed HTML directly (for interactive charts)
        chart_markdown = result['chart_data']
    
    # Include in agent response
    response_text = f"Here's the data visualized:\n\n{chart_markdown}\n\n{explanation}"
```

**Return Format:**
```python
{
    "success": True,
    "chart_type": "bar",
    "output_format": "base64_png" | "html",
    "chart_data": "base64_encoded_string" | "html_string",
    "metadata": {
        "width": 800,
        "height": 600,
        "data_points": 10,
        "series_count": 1
    }
}
```

**When to Use:**
- Comparing multiple values or categories
- Showing trends over time
- Displaying distributions or proportions
- User explicitly requests a chart or graph
- Data would be clearer as a chart than as text

**Agent Integration:**
Agents should intelligently choose to use visualization when:
1. User explicitly requests: "show me a chart", "graph this", "visualize the data"
2. Comparison scenarios: Comparing multiple values, categories, or time periods
3. Trend analysis: Time series data, growth patterns, seasonal variations
4. Distribution display: Showing proportions, percentages, frequency distributions
5. Complex numerical data: When tabular data would be clearer as a chart

### Enhancement Tools (`orchestrator/tools/enhancement_tools.py`)
**Backend gRPC tools for query and context enhancement**

- `expand_query_tool(query)` - Expand search query into semantic variations
- `search_conversation_cache_tool(query, user_id)` - Search conversation history for previous research/chat work before doing new searches

**Usage**:
```python
from orchestrator.tools.enhancement_tools import expand_query_tool, search_conversation_cache_tool

expanded = await expand_query_tool("keyboard matrix circuit")
cached = await search_conversation_cache_tool("What did we discuss about ESP32?", user_id)
```

### Project Content Management Tools (`orchestrator/tools/project_content_tools.py`)
**Tools for intelligently managing project content across multiple files**

- `save_or_update_project_content(result, project_plan_document_id, referenced_context, documents, user_id, metadata)` - Intelligently save/update content in appropriate files
- `determine_content_target(response_text, frontmatter, referenced_context, documents)` - Determine which file and section to update based on content type
- `propose_section_update(document_id, existing_content, section_name, new_content, user_id, ...)` - Propose an update to an existing section
- `append_project_content(document_id, section_name, content, user_id, ...)` - Append new content to a project file
- `create_new_project_file(file_suggestion, project_plan_document_id, initial_content, project_plan_frontmatter, user_id, metadata)` - Create a new project file based on user approval

**Usage**:
```python
from orchestrator.tools.project_content_tools import save_or_update_project_content

# Automatically save/update project content after generating response
await save_or_update_project_content(
    result=agent_response,
    project_plan_document_id=project_plan_id,
    referenced_context=referenced_files,
    documents=search_results,
    user_id=user_id,
    metadata={"shared_memory": shared_memory, "active_editor": active_editor}
)
```

### Reference File Loader (`orchestrator/tools/reference_file_loader.py`)
**Universal tool for loading referenced files from frontmatter using TRUE FILESYSTEM PATH RESOLUTION**

**Key Features:**
- âœ… **True filesystem path resolution** - Deterministic, fast, specific (not semantic search)
- âœ… **Relative path support** - `./file.md` (same directory), `../file.md` (parent directory)
- âœ… **Bare filename normalization** - `file.md` automatically treated as `./file.md` (same directory)
- âœ… **Cascade support** - Load primary file, then load its referenced files (e.g., outline â†’ rules/style/characters)
- âœ… **Universal** - Works for **ALL agents** with configurable reference fields
- âœ… **Backend RPC** - Uses `FindDocumentByPath` gRPC tool for reliable path-to-document lookup

**Core Function:**
- `load_referenced_files(active_editor, user_id, reference_config, doc_type_filter, cascade_config)` - Load referenced files from active editor frontmatter

**Path Resolution:**
- **Requires `canonical_path`** in `active_editor` - automatically provided by frontend when document is open
- Uses `active_editor["canonical_path"]` to determine base directory (e.g., `/app/uploads/Users/admin/Projects/MyProject/`)
- Resolves relative paths from that base directory (e.g., `./file.md` â†’ `/app/uploads/Users/admin/Projects/MyProject/file.md`)
- Finds documents by actual filesystem path using backend `FindDocumentByPath` RPC (not semantic search)
- Returns document_id and full content for each referenced file

**Important:** If `canonical_path` is missing from `active_editor`, path resolution will fail. The frontend automatically includes `canonical_path` when sending active editor context, so agents don't need to set it manually.

**Usage Examples:**

**Electronics Agent** (components, protocols, schematics):
```python
from orchestrator.tools.reference_file_loader import load_referenced_files

reference_config = {
    "components": ["components", "component"],
    "protocols": ["protocols", "protocol"],
    "schematics": ["schematics", "schematic"],
    "specifications": ["specifications", "spec"],
    "other": ["files", "references", "docs"]
}

result = await load_referenced_files(
    active_editor=active_editor,
    user_id=user_id,
    reference_config=reference_config,
    doc_type_filter="electronics"
)

loaded_files = result.get("loaded_files", {})
# Returns: {"components": [...], "protocols": [...], "schematics": [...], ...}
```

**Fiction Editing Agent** (with cascade: outline â†’ rules/style/characters):
```python
from orchestrator.tools.reference_file_loader import load_referenced_files

reference_config = {
    "outline": ["outline"]
}

# Cascading: outline file's frontmatter contains rules, style, characters
cascade_config = {
    "outline": {
        "rules": ["rules"],
        "style": ["style"],
        "characters": ["characters", "character_*"]  # Supports wildcards
    }
}

result = await load_referenced_files(
    active_editor=active_editor,
    user_id=user_id,
    reference_config=reference_config,
    doc_type_filter="fiction",
    cascade_config=cascade_config  # Enables cascading
)

loaded_files = result.get("loaded_files", {})
# Returns: {
#   "outline": [...],      # Primary file
#   "rules": [...],        # Cascaded from outline
#   "style": [...],        # Cascaded from outline
#   "characters": [...]    # Cascaded from outline
# }
```

**Frontmatter Format Requirements:**
- **Always use relative paths** in frontmatter: `./file.md` or `../file.md`
- **Bare filenames** (e.g., `file.md`) are normalized to `./file.md` (same directory)
- **Path format**: Use `./` prefix for same directory, `../` for parent directory

**Example Frontmatter:**
```yaml
---
type: electronics
title: Project Plan
files:
  - ./component_list.md
  - ./wiring_diagram.md
components:
  - ./component_list.md
  - ./digital_control_specifications.md
protocols:
  - ./cat6_network_protocol.md
schematics:
  - ./wiring_diagram.md
---
```

### Frontmatter Utilities (`orchestrator/utils/frontmatter_utils.py`)
**CRITICAL: Always use these utilities when updating frontmatter - never use regex or string manipulation!**

**Why use these utilities:**
- âœ… Preserves all existing frontmatter fields (no data loss)
- âœ… Handles complex YAML structures (lists, nested objects)
- âœ… Prevents duplicate entries automatically
- âœ… Graceful fallback for malformed YAML
- âœ… Properly formatted output

**Available Functions:**

1. **`update_frontmatter_field()`** - Main function for updating any frontmatter fields
   ```python
   from orchestrator.utils.frontmatter_utils import update_frontmatter_field
   
   # Update scalar fields and lists
   updated_content, success = await update_frontmatter_field(
       content=document_content,
       field_updates={"title": "New Title", "status": "published"},
       list_updates={"files": ["./new_file.md"], "components": ["./component.md"]}
   )
   ```

2. **`add_to_frontmatter_list()`** - Convenience function for adding items to lists
   ```python
   from orchestrator.utils.frontmatter_utils import add_to_frontmatter_list
   
   # Add file reference (automatically also adds to 'files' list)
   updated_content, success = await add_to_frontmatter_list(
       content=project_plan_content,
       list_key="components",
       new_items=["./new_component.md"]
   )
   ```

3. **`parse_frontmatter()`** - Read-only parsing (no modifications)
   ```python
   from orchestrator.utils.frontmatter_utils import parse_frontmatter
   
   frontmatter, body = await parse_frontmatter(document_content)
   title = frontmatter.get("title")
   files = frontmatter.get("files", [])
   ```

**Complete Example - Updating Project Plan Frontmatter:**
```python
from orchestrator.utils.frontmatter_utils import add_to_frontmatter_list
from orchestrator.tools.document_tools import get_document_content_tool, update_document_content_tool

# Get current content
content = await get_document_content_tool(document_id, user_id)

# Add new file reference to both specific list and 'files' list
updated_content, success = await add_to_frontmatter_list(
    content=content,
    list_key="components",  # or "protocols", "schematics", etc.
    new_items=["./new_component.md"],
    also_update_files=True  # Also adds to 'files' list for active editor context
)

# Save updated content
if success:
    await update_document_content_tool(
        document_id=document_id,
        content=updated_content,
        user_id=user_id,
        append=False
    )
```

**âŒ NEVER DO THIS:**
- Don't use regex to parse/update frontmatter
- Don't manually rebuild frontmatter strings
- Don't overwrite entire frontmatter blocks
- Don't use string replacement for list updates

**âœ… ALWAYS DO THIS:**
- Use `update_frontmatter_field()` or `add_to_frontmatter_list()`
- Let the utility handle YAML parsing and serialization
- Trust the utility to preserve all existing fields

**Cascade Example (Fiction):**
```yaml
# manuscript.md
---
type: fiction
outline: ./outline.md
---

# outline.md (loaded first, then cascades)
---
type: outline
rules: ./rules.md
style: ./style.md
characters:
  - ./characters/alex.md
  - ./characters/maya.md
---
```

The system will:
1. Load `outline.md` (primary reference)
2. Parse its frontmatter
3. Load `rules.md`, `style.md`, and character files (cascaded references)

### Project Structure Management Tools (`orchestrator/tools/project_structure_tools.py`)
**Tools for planning and creating project file structures**

- `plan_project_structure(query, user_id, llm, project_type, default_folder)` - Use LLM to intelligently plan project structure, files, and organization
- `execute_project_structure_plan(plan, query, user_id, project_type, project_category, project_plan_sections)` - Execute the project structure plan by creating files and folders

**Note**: `execute_project_structure_plan` automatically generates frontmatter with proper relative paths (`./filename.md`) for use with `load_referenced_files`.

**Usage**:
```python
from orchestrator.tools.project_structure_tools import (
    plan_project_structure,
    execute_project_structure_plan
)

# Plan project structure using LLM
result = await plan_project_structure(
    query="I need to create a new electronics project for an Allen organ control system",
    user_id=user_id,
    llm=llm_instance,
    project_type="electronics",
    default_folder="Projects"
)

if result.get("success"):
    plan = result.get("plan")
    
    # Execute the plan to create files
    execution_result = await execute_project_structure_plan(
        plan=plan,
        query=original_query,
        user_id=user_id,
        project_type="electronics",
        project_category="electronics"
    )
```

### Org-Mode Tools (Backend)
**BULLY! Tools for managing user's Org-mode inbox and searching reference files!**

- `search_org_files(query, tags, todo_states, limit)` - Search across all user's .org files
- `list_org_todos(todo_states, tags, limit)` - List all TODO items from org files
- `search_org_by_tag(tag, limit)` - Search org files by specific tag
- `org_inbox_list_items()` - List tasks from inbox.org
- `org_inbox_add_item(text, kind)` - Add checkbox or TODO to inbox.org
- `org_inbox_toggle_done(line_index)` - Toggle task state
- `org_inbox_append_text(content)` - Append Org-mode content
- `org_inbox_set_state(line_index, state)` - Set TODO state

### Image & Messaging Tools (Backend)
**BULLY! Tools for visual generation and messaging cavalry!**

- `generate_image(prompt, size, format, num_images)` - Generate images via OpenRouter
- `get_user_rooms(user_id, limit)` - Get list of chat rooms
- `send_room_message(user_id, room_id, message_content, message_type)` - Send message to room

## Available Utilities by Category

### Project Utilities (`orchestrator/utils/project_utils.py`)
**Pure utility functions for project content generation**

- `sanitize_filename(filename)` - Sanitize filename (preserves spaces, removes problematic chars)
- `generate_filename_from_content(content, content_type)` - Generate filename from content
- `generate_title_from_content(content, content_type)` - Generate title from content
- `extract_description_from_content(content)` - Extract description (first sentence)

**Usage**:
```python
from orchestrator.utils.project_utils import (
    sanitize_filename,
    generate_filename_from_content,
    generate_title_from_content,
    extract_description_from_content
)

# Sanitize filename (preserves spaces)
safe_name = sanitize_filename("My Project - Component Spec.md")
# Returns: "My Project - Component Spec.md"

# Generate filename from content
filename = generate_filename_from_content(
    "The Keyboard Matrix circuit uses...",
    "component"
)
# Returns: "Keyboard Matrix component.md"

# Generate title
title = generate_title_from_content(
    "The Keyboard Matrix circuit uses...",
    "component"
)
# Returns: "Keyboard Matrix - Component"

# Extract description
desc = extract_description_from_content(
    "The keyboard scanning matrix uses a 8x8 grid. It connects..."
)
# Returns: "The keyboard scanning matrix uses a 8x8 grid."
```

## Tool Access Patterns

### For LLM Orchestrator Agents
**Import tools directly from modules**:
```python
from orchestrator.tools.document_tools import search_documents_structured
from orchestrator.utils.project_utils import sanitize_filename

# Use directly
results = await search_documents_structured(query, user_id)
safe_name = sanitize_filename(filename)
```

### For Backend Agents (LangGraph)
**Use centralized tool registry**:
```python
from services.langgraph_tools.centralized_tool_registry import get_tool_registry

tool_registry = await get_tool_registry()
search_tool = tool_registry.get_tool_function("search_documents", AgentType.RESEARCH_AGENT)
```

## Tool Development Guidelines

### Creating New Tools

1. **Determine tool type**:
   - Needs backend/gRPC? â†’ `orchestrator/tools/`
   - Pure function? â†’ `orchestrator/utils/`

2. **Follow naming conventions**:
   - Tools: `*_tool` suffix (e.g., `create_user_file_tool`)
   - Utilities: descriptive names (e.g., `sanitize_filename`)

3. **Add to exports**:
   - Tools: Add to `orchestrator/tools/__init__.py`
   - Utilities: Add to module `__all__` if needed

4. **Document usage**:
   - Add docstrings with examples
   - Update this reference document
   - Include in agent prompts if commonly used

### Tool Documentation Requirements

**All tools MUST have**:
- Clear docstring with Args/Returns
- Usage examples in docstring
- Type hints for all parameters
- Error handling documentation

**Example**:
```python
async def create_user_file_tool(
    filename: str,
    content: str,
    folder_path: Optional[str] = None,
    user_id: str = "system"
) -> Dict[str, Any]:
    """
    Create a file in the user's My Documents section
    
    Args:
        filename: Name of the file to create (e.g., "sensor_spec.md")
        content: File content as string
        folder_path: Optional folder path (e.g., "Projects/Electronics")
        user_id: User ID (required - must match the user making the request)
    
    Returns:
        Dict with success, document_id, filename, and message
        
    Example:
        >>> result = await create_user_file_tool(
        ...     filename="component.md",
        ...     content="# Component",
        ...     folder_path="Projects",
        ...     user_id="user123"
        ... )
        >>> result["success"]
        True
    """
```

## Tool Categories Summary

| Category | Location | Type | Examples |
|----------|----------|------|----------|
| Document Operations | `tools/document_tools.py` | gRPC | search, get content |
| Document Editing | `tools/document_editing_tools.py` | gRPC | update, propose edits |
| File Creation | `tools/file_creation_tools.py` | gRPC | create file, create folder |
| Web Search | `tools/web_tools.py` | gRPC | search web, crawl |
| Query Enhancement | `tools/enhancement_tools.py` | gRPC | expand query, cache search |
| Project Content Management | `tools/project_content_tools.py` | gRPC | save/update content, determine target, enrich metadata |
| Project Structure Management | `tools/project_structure_tools.py` | gRPC | plan structure, execute plan, load referenced context |
| Project Utilities | `utils/project_utils.py` | Pure | filename gen, sanitize |

## Best Practices

1. **Use the right tool type**: Don't create gRPC tools for pure functions
2. **Import directly**: LLM orchestrator agents import tools directly
3. **Handle errors**: All tools return Dict with success/error fields
4. **Document usage**: Add examples to docstrings and this reference
5. **Keep utilities pure**: Utils should have no side effects or backend calls
6. **Test independently**: Tools and utilities should be testable in isolation

## Updating This Reference

**When adding new tools**:
1. Add to appropriate category section
2. Include usage example
3. Document parameters and return values
4. Note if it's gRPC-backed or pure utility

**When modifying existing tools**:
1. Update the relevant section
2. Note breaking changes
3. Update examples if behavior changed
