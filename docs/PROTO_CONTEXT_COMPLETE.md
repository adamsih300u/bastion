# Proto Context Design - Complete ‚úÖ

## What We Built

A comprehensive gRPC proto schema that supports **conditional context** for all LangGraph agent needs.

---

## Proto Structure Summary

### ChatRequest Message

**15 Fields** organized into logical groups:

#### Core Identity (Always Required - 4 fields)
1. `user_id` - User UUID
2. `conversation_id` - Conversation UUID  
3. `query` - Current user query
4. `session_id` - Session identifier

#### Routing Control (Optional - 2 fields)
5. `agent_type` - Explicit agent selection
6. `routing_reason` - Why this agent was chosen

#### Context Fields (Optional - 9 fields)
7. `conversation_history` - List of past messages
8. `persona` - User preferences (ai_name, style, bias)
9. `active_editor` - Editor context with file content
10. `pipeline_context` - Pipeline execution context
11. `permission_grants` - HITL permission flags
12. `pending_operations` - Operations awaiting approval
13. `conversation_intelligence` - Performance cache
14. `locked_agent` - Conversation routing lock
15. `base_checkpoint_id` - For conversation branching

---

## Supporting Message Types (13 messages)

### User Context
- `UserPersona` - Preferences and personalization
- `ConversationMessage` - Individual message in history

### Editor Context (Fiction, Proofreading, etc.)
- `ActiveEditor` - Editor state with content
- `EditorFrontmatter` - YAML metadata from markdown

### Pipeline Context (Template Execution)
- `PipelineContext` - Pipeline ID and variables

### HITL Context
- `PermissionGrants` - What operations are allowed
- `PendingOperationInfo` - Operations awaiting approval

### Performance Optimization
- `ConversationIntelligence` - Cached results
- `CachedResult` - Individual cached item
- `TopicContinuity` - Topic tracking
- `TopicTransition` - Topic change events
- `ResearchCache` - Research result cache

---

## Context by Page Type

### Chat Page
```
‚úÖ Core fields
‚úÖ conversation_history
‚úÖ persona
‚úÖ permission_grants (if any)
‚úÖ pending_operations (if any)
```

**Result**: ~1-5KB per request

### Editor Page (`/editor/chapter1.md`)
```
‚úÖ Core fields
‚úÖ conversation_history
‚úÖ persona
‚úÖ active_editor (with full content!)
‚úÖ permission_grants (if any)
‚úÖ pending_operations (if any)
```

**Result**: ~10-100KB per request (depending on file size)

**Agents**: Fiction editing, proofreading, story analysis, character development

### Pipeline Page (`/pipelines/123`)
```
‚úÖ Core fields
‚úÖ conversation_history
‚úÖ persona
‚úÖ pipeline_context (pipeline_id, variables)
‚úÖ permission_grants (if any)
‚úÖ pending_operations (if any)
```

**Result**: ~1-10KB per request

**Agents**: Pipeline agent (template execution)

### Wargaming Session (Locked Agent)
```
‚úÖ Core fields
‚úÖ conversation_history (critical!)
‚úÖ persona
‚úÖ locked_agent = "wargaming_agent"
‚úÖ permission_grants (if any)
‚úÖ pending_operations (if any)
```

**Result**: ~1-5KB per request

**Agents**: Wargaming agent (session continuity)

---

## Key Design Principles

### ‚úÖ Conditional Fields (Option B)
- All context fields are optional
- Backend sends only relevant context
- Optimizes message size
- Extensible for future needs

### ‚úÖ Structured Data
- No more `map<string, string> metadata`
- Typed message structures
- Proto validation and type safety
- Clear documentation

### ‚úÖ Extensibility
- `custom_fields` maps for future extensions
- New context without proto changes
- Backward compatible

### ‚úÖ Performance Aware
- Filter conversation intelligence to relevant results
- Limit conversation history to last 20 messages
- Optional fields minimize payload size

---

## What This Enables

### Now Possible
1. ‚úÖ **Fiction Editing** - llm-orchestrator receives full editor content
2. ‚úÖ **Pipeline Execution** - llm-orchestrator knows which templates to use
3. ‚úÖ **HITL Permissions** - llm-orchestrator knows what's allowed
4. ‚úÖ **Conversation Continuity** - Full history for context
5. ‚úÖ **Personalization** - User preferences for response style
6. ‚úÖ **Session Locking** - Wargaming, dedicated agent sessions
7. ‚úÖ **Performance Optimization** - Cached results to avoid redundant work

### Future Capabilities
1. üîÆ **Intent Classification in llm-orchestrator** - Has full context to decide
2. üîÆ **Remove Backend LangGraph** - All agent logic in llm-orchestrator
3. üîÆ **Stateless Backend** - Pure data access + API layer
4. üîÆ **Scalable llm-orchestrator** - Can run multiple instances
5. üîÆ **Advanced Context** - Add more fields as needed

---

## Documentation

### Created Files
1. ‚úÖ `/opt/bastion/protos/orchestrator.proto` - Complete proto schema
2. ‚úÖ `/opt/bastion/docs/PROTO_CONTEXT_USAGE_GUIDE.md` - How to use each field
3. ‚úÖ `/opt/bastion/docs/LANGGRAPH_CONTEXT_ANALYSIS.md` - Current state analysis
4. ‚úÖ `/opt/bastion/docs/PROTO_CONTEXT_COMPLETE.md` - This summary

### Updated Files
1. ‚úÖ `/opt/bastion/docs/LANGGRAPH_AGENT_MIGRATION_GUIDE.md` - References new proto

---

## Next Steps

### Phase 1: Backend Context Gathering ‚è≠Ô∏è
Update backend to populate new proto fields:
- Extract conversation history from LangGraph state
- Build persona from user settings
- Conditionally add editor context
- Conditionally add pipeline context
- Add permission grants and pending operations

### Phase 2: llm-orchestrator Context Usage ‚è≠Ô∏è
Update llm-orchestrator to use received context:
- Parse conversation history for agents
- Use persona for personalization
- Pass editor context to fiction agents
- Pass pipeline context to pipeline agent
- Use permissions for HITL decisions

### Phase 3: Intent Classification Migration ‚è≠Ô∏è
Move intent classifier to llm-orchestrator:
- Receives full context from backend
- Makes routing decisions with context
- Backend becomes thin proxy

### Phase 4: Remove Backend LangGraph ‚è≠Ô∏è
Gradually remove backend agents:
- All agents run in llm-orchestrator
- Backend handles only data access
- Pure microservices architecture

---

## Current Status

| Component | Status | Notes |
|-----------|--------|-------|
| Proto Schema | ‚úÖ Complete | All fields defined |
| Usage Guide | ‚úÖ Complete | Documentation written |
| Backend Implementation | ‚è≠Ô∏è Next | Need context gathering |
| llm-orchestrator Implementation | ‚è≠Ô∏è Next | Need context parsing |
| Intent Classifier Migration | ‚è≠Ô∏è Future | Phase 3 |
| Backend LangGraph Removal | ‚è≠Ô∏è Future | Phase 4 |

---

## Migration Impact

### What Changes
- ‚ùå Old: `map<string, string> metadata` (untyped)
- ‚úÖ New: Structured proto messages (typed)

### What Stays Same
- ‚úÖ Core fields: user_id, conversation_id, query
- ‚úÖ gRPC streaming interface
- ‚úÖ Existing agents continue working

### What Gets Better
- ‚úÖ Type safety and validation
- ‚úÖ Clear documentation
- ‚úÖ Extensibility for future needs
- ‚úÖ Optimized payload sizes

---

## Compatibility

### Backward Compatible ‚úÖ
- Old requests still work (core fields unchanged)
- New fields are optional
- llm-orchestrator can handle both old and new format
- Gradual rollout possible

### Forward Compatible ‚úÖ
- `custom_fields` maps for extensions
- New agent types can be added
- New context fields can be added
- No breaking changes needed

---

**BULLY! A well-organized proto is like a well-organized cavalry - every field knows its role and executes it perfectly!** üéØ

