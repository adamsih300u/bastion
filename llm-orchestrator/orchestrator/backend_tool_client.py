"""
Backend Tool Client - gRPC client for accessing backend data services
"""

import logging
import os
import json
from typing import List, Dict, Any, Optional
import asyncio

import grpc
from protos import tool_service_pb2, tool_service_pb2_grpc

# For type hints
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from typing import List as TypingList

logger = logging.getLogger(__name__)


class BackendToolClient:
    """
    gRPC client for backend tool service
    
    Provides async methods to access backend data services:
    - Document search and retrieval
    - RSS feed operations
    - Entity operations
    - Weather data
    - Org-mode operations
    """
    
    def __init__(self, host: str = None, port: int = None):
        """
        Initialize backend tool client
        
        Args:
            host: Backend service host (defaults to env BACKEND_TOOL_SERVICE_HOST)
            port: Backend service port (defaults to env BACKEND_TOOL_SERVICE_PORT)
        """
        self.host = host or os.getenv('BACKEND_TOOL_SERVICE_HOST', 'backend')
        self.port = port or int(os.getenv('BACKEND_TOOL_SERVICE_PORT', '50052'))
        self.address = f'{self.host}:{self.port}'
        self._channel: Optional[grpc.aio.Channel] = None
        self._stub: Optional[tool_service_pb2_grpc.ToolServiceStub] = None
        
        logger.info(f"Backend Tool Client configured for {self.address}")
    
    async def connect(self):
        """Establish connection to backend tool service"""
        if self._channel is None:
            logger.debug(f"Connecting to backend tool service at {self.address}...")
            # Increase message size limits for large responses (default is 4MB)
            options = [
                ('grpc.max_send_message_length', 100 * 1024 * 1024),  # 100 MB
                ('grpc.max_receive_message_length', 100 * 1024 * 1024),  # 100 MB
            ]
            self._channel = grpc.aio.insecure_channel(self.address, options=options)
            self._stub = tool_service_pb2_grpc.ToolServiceStub(self._channel)
            logger.debug(f"âœ… Connected to backend tool service")
    
    async def close(self):
        """Close connection to backend tool service"""
        if self._channel:
            await self._channel.close()
            self._channel = None
            self._stub = None
            logger.debug("Disconnected from backend tool service")
    
    async def _ensure_connected(self):
        """Ensure connection is established"""
        if self._stub is None:
            await self.connect()
    
    # ===== Document Operations =====
    
    async def search_documents(
        self,
        query: str,
        user_id: str = "system",
        limit: int = 10,
        filters: List[str] = None
    ) -> Dict[str, Any]:
        """
        Search documents by query
        
        Args:
            query: Search query
            user_id: User ID for access control
            limit: Maximum number of results
            filters: Optional filters
            
        Returns:
            Dict with 'results' (list of documents) and 'total_count'
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.SearchRequest(
                user_id=user_id,
                query=query,
                limit=limit,
                filters=filters or []
            )
            
            response = await self._stub.SearchDocuments(request)
            
            # Convert proto response to dict
            results = []
            for doc in response.results:
                results.append({
                    'document_id': doc.document_id,
                    'title': doc.title,
                    'filename': doc.filename,
                    'content_preview': doc.content_preview,
                    'relevance_score': doc.relevance_score,
                    'metadata': dict(doc.metadata)
                })
            
            return {
                'results': results,
                'total_count': response.total_count
            }
            
        except grpc.RpcError as e:
            logger.error(f"Document search failed: {e.code()} - {e.details()}")
            return {'results': [], 'total_count': 0, 'error': str(e)}
        except Exception as e:
            logger.error(f"Unexpected error in document search: {e}")
            return {'results': [], 'total_count': 0, 'error': str(e)}
    
    async def get_document(
        self,
        document_id: str,
        user_id: str = "system"
    ) -> Optional[Dict[str, Any]]:
        """
        Get document metadata
        
        Args:
            document_id: Document ID
            user_id: User ID for access control
            
        Returns:
            Document metadata dict or None
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.DocumentRequest(
                document_id=document_id,
                user_id=user_id
            )
            
            response = await self._stub.GetDocument(request)
            
            return {
                'document_id': response.document_id,
                'title': response.title,
                'filename': response.filename,
                'content_type': response.content_type,
                'metadata': dict(response.metadata)
            }
            
        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.NOT_FOUND:
                logger.warning(f"Document not found: {document_id}")
                return None
            logger.error(f"Get document failed: {e.code()} - {e.details()}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error getting document: {e}")
            return None
    
    async def get_document_content(
        self,
        document_id: str,
        user_id: str = "system"
    ) -> Optional[str]:
        """
        Get full document content
        
        Args:
            document_id: Document ID
            user_id: User ID for access control
            
        Returns:
            Document content string or None
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.DocumentRequest(
                document_id=document_id,
                user_id=user_id
            )
            
            response = await self._stub.GetDocumentContent(request)
            
            return response.content
            
        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.NOT_FOUND:
                logger.warning(f"Document content not found: {document_id}")
                return None
            logger.error(f"Get document content failed: {e.code()} - {e.details()}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error getting document content: {e}")
            return None
    
    async def get_document_size(self, document_id: str, user_id: str = "system") -> int:
        """
        Get total character count of a document
        
        Args:
            document_id: Document ID
            user_id: User ID for access control
            
        Returns:
            Total character count, or 0 if not found or error
        """
        try:
            # Get full document content and calculate size
            content = await self.get_document_content(document_id, user_id)
            if content:
                return len(content)
            return 0
            
        except Exception as e:
            logger.error(f"Failed to get document size: {e}")
            return 0
    
    async def get_document_chunks(
        self,
        document_id: str,
        user_id: str = "system",
        limit: Optional[int] = 5
    ) -> List[Dict[str, Any]]:
        """
        Get multiple chunks from a specific document, sorted by chunk_index
        
        Args:
            document_id: Document ID to retrieve chunks from
            user_id: User ID for access control
            limit: Maximum number of chunks to return (None = all chunks)
            
        Returns:
            List of chunk dictionaries with content, chunk_index, etc.
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.DocumentRequest(
                document_id=document_id,
                user_id=user_id
            )
            
            response = await self._stub.GetDocumentChunks(request)
            
            # Convert proto response to list of dicts
            chunks = []
            for chunk_proto in response.chunks:
                # Parse metadata JSON string
                metadata = {}
                if chunk_proto.metadata:
                    try:
                        import json
                        metadata = json.loads(chunk_proto.metadata)
                    except:
                        pass
                
                chunks.append({
                    'chunk_id': chunk_proto.chunk_id,
                    'document_id': chunk_proto.document_id,
                    'content': chunk_proto.content,
                    'chunk_index': chunk_proto.chunk_index,
                    'metadata': metadata
                })
            
            # Apply limit if specified
            if limit is not None:
                chunks = chunks[:limit]
            
            logger.info(f"Retrieved {len(chunks)} chunks for document {document_id}")
            return chunks
            
        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.NOT_FOUND:
                logger.warning(f"Document chunks not found: {document_id}")
                return []
            logger.error(f"Get document chunks failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error getting document chunks: {e}")
            return []
    
    async def find_document_by_path(
        self,
        file_path: str,
        user_id: str = "system",
        base_path: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Find a document by filesystem path (true path resolution).
        
        Args:
            file_path: Relative or absolute filesystem path (e.g., "./component_list.md", "../file.md")
            user_id: User ID for access control
            base_path: Base directory for resolving relative paths (optional)
            
        Returns:
            Dict with document_id, filename, resolved_path, or None if not found
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.FindDocumentByPathRequest(
                user_id=user_id,
                file_path=file_path,
                base_path=base_path or ""
            )
            
            response = await self._stub.FindDocumentByPath(request)
            
            if not response.success:
                logger.warning(f"Document not found by path: {file_path} - {response.error}")
                return None
            
            return {
                'document_id': response.document_id,
                'filename': response.filename,
                'resolved_path': response.resolved_path
            }
            
        except grpc.RpcError as e:
            logger.error(f"Find document by path failed: {e.code()} - {e.details()}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error finding document by path: {e}")
            return None

    async def find_documents_by_tags(
        self,
        required_tags: List[str],
        user_id: str = "system",
        collection_type: str = "",
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        Find documents that contain ALL of the specified tags

        Args:
            required_tags: List of tags that ALL must be present
            user_id: User ID for access control
            collection_type: Collection type filter ("user", "global", or empty)
            limit: Maximum number of results

        Returns:
            List of document dictionaries with metadata
        """
        try:
            await self._ensure_connected()

            request = tool_service_pb2.FindDocumentsByTagsRequest(
                user_id=user_id,
                required_tags=required_tags,
                collection_type=collection_type,
                limit=limit
            )

            response = await self._stub.FindDocumentsByTags(request)

            # Convert response to list of dicts
            documents = []
            for result in response.results:
                doc = {
                    'document_id': result.document_id,
                    'title': result.title,
                    'filename': result.filename,
                    'content_preview': result.content_preview,
                    'relevance_score': result.relevance_score,
                    'metadata': dict(result.metadata)
                }
                documents.append(doc)

            logger.info(f"Found {len(documents)} documents with tags {required_tags}")
            return documents

        except grpc.RpcError as e:
            logger.error(f"Find documents by tags failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error finding documents by tags: {e}")
            return []
    
    # ===== File Creation Operations =====
    
    async def create_user_file(
        self,
        filename: str,
        content: str,
        user_id: str = "system",
        folder_id: Optional[str] = None,
        folder_path: Optional[str] = None,
        title: Optional[str] = None,
        tags: Optional[List[str]] = None,
        category: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Create a file in the user's My Documents section
        
        Args:
            filename: Name of the file to create
            content: File content as string
            user_id: User ID (required)
            folder_id: Optional folder ID to place file in
            folder_path: Optional folder path (e.g., "Projects/Electronics") - will create if needed
            title: Optional document title (defaults to filename)
            tags: Optional list of tags for the document
            category: Optional category for the document
        
        Returns:
            Dict with success, document_id, filename, folder_id, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.CreateUserFileRequest(
                user_id=user_id,
                filename=filename,
                content=content,
                folder_id=folder_id if folder_id else "",
                folder_path=folder_path if folder_path else "",
                title=title if title else "",
                tags=tags if tags else [],
                category=category if category else ""
            )
            
            response = await self._stub.CreateUserFile(request)
            
            return {
                "success": response.success,
                "document_id": response.document_id,
                "filename": response.filename,
                "folder_id": response.folder_id,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Create user file failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to create file"
            }
        except Exception as e:
            logger.error(f"Unexpected error creating user file: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to create file"
            }
    
    async def create_user_folder(
        self,
        folder_name: str,
        user_id: str = "system",
        parent_folder_id: Optional[str] = None,
        parent_folder_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Create a folder in the user's My Documents section
        
        Args:
            folder_name: Name of the folder to create
            user_id: User ID (required)
            parent_folder_id: Optional parent folder ID
            parent_folder_path: Optional parent folder path (e.g., "Projects") - will resolve to folder_id
        
        Returns:
            Dict with success, folder_id, folder_name, parent_folder_id, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.CreateUserFolderRequest(
                user_id=user_id,
                folder_name=folder_name,
                parent_folder_id=parent_folder_id if parent_folder_id else "",
                parent_folder_path=parent_folder_path if parent_folder_path else ""
            )
            
            response = await self._stub.CreateUserFolder(request)
            
            return {
                "success": response.success,
                "folder_id": response.folder_id,
                "folder_name": response.folder_name,
                "parent_folder_id": response.parent_folder_id if response.parent_folder_id else None,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Create user folder failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to create folder"
            }
        except Exception as e:
            logger.error(f"Unexpected error creating user folder: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to create folder"
            }
    
    # ===== Document Editing Operations =====
    
    async def update_document_metadata(
        self,
        document_id: str,
        user_id: str = "system",
        title: Optional[str] = None,
        frontmatter_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Update document title and/or frontmatter type
        
        Args:
            document_id: Document ID to update
            user_id: User ID (required - must match document owner)
            title: Optional new title
            frontmatter_type: Optional frontmatter type (e.g., "electronics", "fiction")
        
        Returns:
            Dict with success, document_id, updated_fields, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.UpdateDocumentMetadataRequest(
                user_id=user_id,
                document_id=document_id,
                title=title if title else "",
                frontmatter_type=frontmatter_type if frontmatter_type else ""
            )
            
            response = await self._stub.UpdateDocumentMetadata(request)
            
            return {
                "success": response.success,
                "document_id": response.document_id,
                "updated_fields": list(response.updated_fields),
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Update document metadata failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to update document metadata"
            }
        except Exception as e:
            logger.error(f"Unexpected error updating document metadata: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to update document metadata"
            }
    
    async def update_document_content(
        self,
        document_id: str,
        content: str,
        user_id: str = "system",
        append: bool = False
    ) -> Dict[str, Any]:
        """
        Update document content (append or replace)
        
        Args:
            document_id: Document ID to update
            content: New content to add (if append=True) or replace entire content (if append=False)
            user_id: User ID (required - must match document owner)
            append: If True, append content to existing; if False, replace entire content
        
        Returns:
            Dict with success, document_id, content_length, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.UpdateDocumentContentRequest(
                user_id=user_id,
                document_id=document_id,
                content=content,
                append=append
            )
            
            response = await self._stub.UpdateDocumentContent(request)
            
            return {
                "success": response.success,
                "document_id": response.document_id,
                "content_length": response.content_length,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Update document content failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to update document content"
            }
        except Exception as e:
            logger.error(f"Unexpected error updating document content: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to update document content"
            }
    
    async def propose_document_edit(
        self,
        document_id: str,
        edit_type: str,
        operations: Optional[List[Dict[str, Any]]] = None,
        content_edit: Optional[Dict[str, Any]] = None,
        agent_name: str = "unknown",
        summary: str = "",
        requires_preview: bool = True,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Propose a document edit for user review
        
        Args:
            document_id: Document ID to edit
            edit_type: "operations" or "content"
            operations: List of EditorOperation dicts (for operation-based edits)
            content_edit: ContentEdit dict (for content-based edits)
            agent_name: Name of proposing agent
            summary: Human-readable summary of proposed changes
            requires_preview: If False and edit is small, frontend may auto-apply
            user_id: User ID (required - must match document owner)
        
        Returns:
            Dict with success, proposal_id, document_id, and message
        """
        try:
            await self._ensure_connected()
            
            # Convert operations to proto
            operations_proto = []
            if operations:
                for op in operations:
                    op_proto = tool_service_pb2.EditorOperationProto(
                        op_type=op.get("op_type", ""),
                        start=op.get("start", 0),
                        end=op.get("end", 0),
                        text=op.get("text", ""),
                        pre_hash=op.get("pre_hash", ""),
                        original_text=op.get("original_text") or "",
                        anchor_text=op.get("anchor_text") or "",
                        left_context=op.get("left_context") or "",
                        right_context=op.get("right_context") or "",
                        occurrence_index=op.get("occurrence_index", 0),
                        note=op.get("note") or "",
                        confidence=op.get("confidence") or 0.0
                    )
                    operations_proto.append(op_proto)
            
            # Convert content_edit to proto
            content_edit_proto = None
            if content_edit:
                content_edit_proto = tool_service_pb2.ContentEditProto(
                    edit_mode=content_edit.get("edit_mode", "append"),
                    content=content_edit.get("content", ""),
                    insert_position=content_edit.get("insert_position") or 0,
                    note=content_edit.get("note") or ""
                )
            
            request = tool_service_pb2.ProposeDocumentEditRequest(
                user_id=user_id,
                document_id=document_id,
                edit_type=edit_type,
                operations=operations_proto,
                content_edit=content_edit_proto,
                agent_name=agent_name,
                summary=summary,
                requires_preview=requires_preview
            )
            
            response = await self._stub.ProposeDocumentEdit(request)
            
            return {
                "success": response.success,
                "proposal_id": response.proposal_id,
                "document_id": response.document_id,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Propose document edit failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to propose document edit"
            }
        except Exception as e:
            logger.error(f"Unexpected error proposing document edit: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to propose document edit"
            }
    
    async def apply_operations_directly(
        self,
        document_id: str,
        operations: List[Dict[str, Any]],
        user_id: str = "system",
        agent_name: str = "unknown"
    ) -> Dict[str, Any]:
        """
        Apply operations directly to a document (for authorized agents only)
        
        Args:
            document_id: Document ID to edit
            operations: List of EditorOperation dicts to apply
            user_id: User ID (required - must match document owner)
            agent_name: Name of agent requesting this operation (for security check)
        
        Returns:
            Dict with success, document_id, applied_count, and message
        """
        try:
            await self._ensure_connected()
            
            # Convert operations to proto
            operations_proto = []
            for op in operations:
                op_proto = tool_service_pb2.EditorOperationProto(
                    op_type=op.get("op_type", "replace_range"),
                    start=op.get("start", 0),
                    end=op.get("end", op.get("start", 0)),
                    text=op.get("text", ""),
                    pre_hash=op.get("pre_hash", "")
                )
                if op.get("original_text"):
                    op_proto.original_text = op["original_text"]
                if op.get("anchor_text"):
                    op_proto.anchor_text = op["anchor_text"]
                if op.get("left_context"):
                    op_proto.left_context = op["left_context"]
                if op.get("right_context"):
                    op_proto.right_context = op["right_context"]
                if op.get("occurrence_index") is not None:
                    op_proto.occurrence_index = op["occurrence_index"]
                if op.get("note"):
                    op_proto.note = op["note"]
                if op.get("confidence") is not None:
                    op_proto.confidence = op["confidence"]
                operations_proto.append(op_proto)
            
            request = tool_service_pb2.ApplyOperationsDirectlyRequest(
                user_id=user_id,
                document_id=document_id,
                operations=operations_proto,
                agent_name=agent_name
            )
            
            response = await self._stub.ApplyOperationsDirectly(request)
            
            return {
                "success": response.success,
                "document_id": response.document_id,
                "applied_count": response.applied_count,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Apply operations directly failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to apply operations directly"
            }
        except Exception as e:
            logger.error(f"Unexpected error applying operations directly: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to apply operations directly"
            }
    
    async def apply_document_edit_proposal(
        self,
        proposal_id: str,
        selected_operation_indices: Optional[List[int]] = None,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Apply an approved document edit proposal
        
        Args:
            proposal_id: ID of proposal to apply
            selected_operation_indices: Which operations to apply (None = all, only for operation-based edits)
            user_id: User ID (required - must match proposal owner)
        
        Returns:
            Dict with success, document_id, applied_count, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.ApplyDocumentEditProposalRequest(
                user_id=user_id,
                proposal_id=proposal_id,
                selected_operation_indices=selected_operation_indices or []
            )
            
            response = await self._stub.ApplyDocumentEditProposal(request)
            
            return {
                "success": response.success,
                "document_id": response.document_id,
                "applied_count": response.applied_count,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Apply document edit proposal failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to apply document edit proposal"
            }
        except Exception as e:
            logger.error(f"Unexpected error applying document edit proposal: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to apply document edit proposal"
            }

    # ===== Weather Operations =====
    
    async def get_weather(
        self,
        location: str,
        user_id: str = "system",
        data_types: List[str] = None,
        date_str: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Get weather data for location
        
        Args:
            location: Location name
            user_id: User ID
            data_types: Types of data to retrieve (e.g., ["current", "forecast", "history"])
            date_str: Optional date string for historical data (YYYY-MM-DD or YYYY-MM)
            
        Returns:
            Weather data dict or None
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.WeatherRequest(
                location=location,
                user_id=user_id,
                data_types=data_types or ["current"]
            )
            
            # Add date_str if provided (for historical requests)
            if date_str:
                request.date_str = date_str
            
            response = await self._stub.GetWeatherData(request)
            
            return {
                'location': response.location,
                'current_conditions': response.current_conditions,
                'forecast': list(response.forecast),
                'alerts': list(response.alerts),
                'metadata': dict(response.metadata),
                'success': True
            }
            
        except grpc.RpcError as e:
            logger.error(f"Get weather failed: {e.code()} - {e.details()}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error getting weather: {e}")
            return None
    
    # ===== Image Generation Operations =====
    
    async def generate_image(
        self,
        prompt: str,
        size: str = "1024x1024",
        format: str = "png",
        seed: Optional[int] = None,
        num_images: int = 1,
        negative_prompt: Optional[str] = None,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Generate images using backend image generation service
        
        Args:
            prompt: Image generation prompt
            size: Image size (e.g., "1024x1024")
            format: Image format (png, jpg, etc.)
            seed: Optional random seed for reproducibility
            num_images: Number of images to generate (1-4)
            negative_prompt: Optional negative prompt
            user_id: User ID
            
        Returns:
            Dict with success, images, and metadata
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.ImageGenerationRequest(
                prompt=prompt,
                size=size,
                format=format,
                num_images=num_images,
                user_id=user_id
            )
            
            # Add optional fields
            if seed is not None:
                request.seed = seed
            if negative_prompt is not None:
                request.negative_prompt = negative_prompt
            
            logger.info(f"Calling backend GenerateImage: prompt={prompt[:100]}...")
            
            response = await self._stub.GenerateImage(request)
            
            # Convert proto response to dict
            result = {
                "success": response.success,
                "model": response.model,
                "prompt": response.prompt,
                "size": response.size,
                "format": response.format,
                "images": []
            }
            
            if response.success:
                for img in response.images:
                    result["images"].append({
                        "filename": img.filename,
                        "path": img.path,
                        "url": img.url,
                        "width": img.width,
                        "height": img.height,
                        "format": img.format
                    })
                logger.info(f"Generated {len(result['images'])} image(s)")
            else:
                result["error"] = response.error
                logger.error(f"Image generation failed: {response.error}")
            
            return result
            
        except grpc.RpcError as e:
            logger.error(f"GenerateImage failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"gRPC error: {e.details()}",
                "images": []
            }
        except Exception as e:
            logger.error(f"Unexpected error in image generation: {e}")
            return {
                "success": False,
                "error": f"gRPC call failed: {str(e)}",
                "images": []
            }
    
    # ===== Entity Operations =====
    
    async def search_entities(
        self,
        query: str,
        user_id: str = "system",
        entity_types: List[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Search entities
        
        Args:
            query: Search query
            user_id: User ID
            entity_types: Types of entities to search
            limit: Maximum results
            
        Returns:
            List of entity dicts
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.EntitySearchRequest(
                user_id=user_id,
                query=query,
                entity_types=entity_types or [],
                limit=limit
            )
            
            response = await self._stub.SearchEntities(request)
            
            entities = []
            for entity in response.entities:
                entities.append({
                    'entity_id': entity.entity_id,
                    'entity_type': entity.entity_type,
                    'name': entity.name,
                    'properties': dict(entity.properties)
                })
            
            return entities
            
        except grpc.RpcError as e:
            logger.error(f"Entity search failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error searching entities: {e}")
            return []
    
    async def get_entity(
        self,
        entity_id: str,
        user_id: str = "system"
    ) -> Optional[Dict[str, Any]]:
        """
        Get entity details
        
        Args:
            entity_id: Entity ID
            user_id: User ID
            
        Returns:
            Entity details dict or None
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.EntityRequest(
                entity_id=entity_id,
                user_id=user_id
            )
            
            response = await self._stub.GetEntity(request)
            
            return {
                'entity': {
                    'entity_id': response.entity.entity_id,
                    'entity_type': response.entity.entity_type,
                    'name': response.entity.name,
                    'properties': dict(response.entity.properties)
                },
                'related_documents': list(response.related_documents)
            }
            
        except grpc.RpcError as e:
            logger.error(f"Get entity failed: {e.code()} - {e.details()}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error getting entity: {e}")
            return None
    
    async def find_documents_by_entities(
        self,
        entity_names: List[str],
        user_id: str = "system"
    ) -> List[str]:
        """
        Find documents mentioning specific entities
        
        Args:
            entity_names: List of entity names to search for
            user_id: User ID for RLS filtering
            
        Returns:
            List of document IDs (RLS filtered)
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.FindDocumentsByEntitiesRequest(
                user_id=user_id,
                entity_names=entity_names
            )
            
            response = await self._stub.FindDocumentsByEntities(request)
            
            logger.info(f"Found {len(response.document_ids)} documents for entities (RLS filtered)")
            return list(response.document_ids)
            
        except grpc.RpcError as e:
            logger.error(f"FindDocumentsByEntities failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error finding documents by entities: {e}")
            return []

    async def find_related_documents_by_entities(
        self,
        entity_names: List[str],
        max_hops: int = 2,
        user_id: str = "system"
    ) -> List[str]:
        """
        Find documents via entity relationship traversal
        
        Args:
            entity_names: Starting entity names
            max_hops: Maximum graph traversal depth (1-2)
            user_id: User ID for RLS filtering
            
        Returns:
            List of document IDs (RLS filtered)
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.FindRelatedDocumentsByEntitiesRequest(
                user_id=user_id,
                entity_names=entity_names,
                max_hops=max_hops
            )
            
            response = await self._stub.FindRelatedDocumentsByEntities(request)
            
            logger.info(f"Found {len(response.document_ids)} related documents (RLS filtered)")
            return list(response.document_ids)
            
        except grpc.RpcError as e:
            logger.error(f"FindRelatedDocumentsByEntities failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error finding related documents: {e}")
            return []

    async def find_co_occurring_entities(
        self,
        entity_names: List[str],
        min_co_occurrences: int = 2,
        user_id: str = "system"
    ) -> List[Dict[str, Any]]:
        """
        Find entities that co-occur with given entities
        
        Args:
            entity_names: Target entity names
            min_co_occurrences: Minimum co-occurrence threshold
            user_id: User ID (for logging/future use)
            
        Returns:
            List of entity dicts with name, type, co_occurrence_count
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.FindCoOccurringEntitiesRequest(
                user_id=user_id,
                entity_names=entity_names,
                min_co_occurrences=min_co_occurrences
            )
            
            response = await self._stub.FindCoOccurringEntities(request)
            
            entities = []
            for entity in response.entities:
                entities.append({
                    "name": entity.name,
                    "type": entity.type,
                    "co_occurrence_count": entity.co_occurrence_count
                })
            
            logger.info(f"Found {len(entities)} co-occurring entities")
            return entities
            
        except grpc.RpcError as e:
            logger.error(f"FindCoOccurringEntities failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error finding co-occurring entities: {e}")
            return []
    
    # ===== Web Operations =====
    
    async def search_web(
        self,
        query: str,
        max_results: int = 15,
        user_id: str = "system"
    ) -> List[Dict[str, Any]]:
        """
        Search the web
        
        Args:
            query: Search query
            max_results: Maximum number of results
            user_id: User ID
            
        Returns:
            List of web search results
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.WebSearchRequest(
                query=query,
                max_results=max_results,
                user_id=user_id
            )
            
            response = await self._stub.SearchWeb(request)
            
            results = []
            for result in response.results:
                results.append({
                    'title': result.title,
                    'url': result.url,
                    'snippet': result.snippet,
                    'content': result.snippet  # WebSearchResult doesn't have content field, use snippet
                })
            
            return results
            
        except grpc.RpcError as e:
            logger.error(f"Web search failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error in web search: {e}")
            return []
    
    async def crawl_web_content(
        self,
        url: str = None,
        urls: List[str] = None,
        user_id: str = "system"
    ) -> List[Dict[str, Any]]:
        """
        Crawl web content from URLs
        
        Args:
            url: Single URL to crawl
            urls: Multiple URLs to crawl
            user_id: User ID
            
        Returns:
            List of crawled content
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.WebCrawlRequest(
                url=url if url else "",
                urls=urls if urls else [],
                user_id=user_id
            )
            
            response = await self._stub.CrawlWebContent(request)
            
            results = []
            for result in response.results:
                results.append({
                    'url': result.url,
                    'title': result.title,
                    'content': result.content,
                    'html': result.html,  # WebCrawlResponse (singular) has html field
                    'metadata': dict(result.metadata)
                })
            
            return results
            
        except grpc.RpcError as e:
            logger.error(f"Web crawl failed: {e.code()} - {e.details()}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error in web crawl: {e}")
            return []
    
    async def crawl_website_recursive(
        self,
        start_url: str,
        max_pages: int = 500,
        max_depth: int = 10,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Recursively crawl entire website
        
        Args:
            start_url: Starting URL for the crawl
            max_pages: Maximum number of pages to crawl
            max_depth: Maximum depth to traverse
            user_id: User ID
            
        Returns:
            Dictionary with crawl results and statistics
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.RecursiveWebsiteCrawlRequest(
                start_url=start_url,
                max_pages=max_pages,
                max_depth=max_depth,
                user_id=user_id
            )
            
            response = await self._stub.CrawlWebsiteRecursive(request)
            
            if not response.success:
                return {
                    "success": False,
                    "error": response.error if response.error else "Unknown error"
                }
            
            # Convert response to dict format
            crawled_pages = []
            for page in response.crawled_pages:
                page_dict = {
                    "url": page.url,
                    "content_type": page.content_type,
                    "markdown_content": page.markdown_content,
                    "html_content": page.html_content,
                    "metadata": dict(page.metadata),
                    "internal_links": list(page.internal_links),
                    "image_links": list(page.image_links),
                    "document_links": list(page.document_links),
                    "depth": page.depth,
                    "crawl_time": page.crawl_time
                }
                if page.parent_url:
                    page_dict["parent_url"] = page.parent_url
                if page.binary_content:
                    page_dict["binary_content"] = bytes(page.binary_content)
                if page.filename:
                    page_dict["filename"] = page.filename
                if page.mime_type:
                    page_dict["mime_type"] = page.mime_type
                if page.size_bytes:
                    page_dict["size_bytes"] = page.size_bytes
                
                crawled_pages.append(page_dict)
            
            return {
                "success": True,
                "start_url": response.start_url,
                "base_domain": response.base_domain,
                "crawl_session_id": response.crawl_session_id,
                "total_items_crawled": response.total_items_crawled,
                "html_pages_crawled": response.html_pages_crawled,
                "images_downloaded": response.images_downloaded,
                "documents_downloaded": response.documents_downloaded,
                "total_items_failed": response.total_items_failed,
                "max_depth_reached": response.max_depth_reached,
                "elapsed_time_seconds": response.elapsed_time_seconds,
                "crawled_pages": crawled_pages
            }
            
        except grpc.RpcError as e:
            logger.error(f"Recursive website crawl failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"gRPC error: {e.details()}"
            }
        except Exception as e:
            logger.error(f"Unexpected error in recursive website crawl: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def crawl_site(
        self,
        seed_url: str,
        query_criteria: str,
        max_pages: int = 50,
        max_depth: int = 2,
        allowed_path_prefix: Optional[str] = None,
        include_pdfs: bool = False,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Domain-scoped crawl starting from seed URL, filtering by query criteria
        
        Args:
            seed_url: Starting URL for the crawl
            query_criteria: Criteria to identify relevant pages
            max_pages: Maximum number of pages to crawl
            max_depth: Maximum depth to traverse
            allowed_path_prefix: Optional path prefix to restrict crawl
            include_pdfs: Whether to include PDFs
            user_id: User ID
            
        Returns:
            Dictionary with crawl results
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.DomainCrawlRequest(
                seed_url=seed_url,
                query_criteria=query_criteria,
                max_pages=max_pages,
                max_depth=max_depth,
                allowed_path_prefix=allowed_path_prefix if allowed_path_prefix else "",
                include_pdfs=include_pdfs,
                user_id=user_id
            )
            
            response = await self._stub.CrawlSite(request)
            
            if not response.success:
                return {
                    "success": False,
                    "error": response.error if response.error else "Unknown error"
                }
            
            # Convert response to dict format
            results = []
            for result in response.results:
                results.append({
                    "url": result.url,
                    "title": result.title,
                    "full_content": result.full_content,
                    "metadata": dict(result.metadata),
                    "relevance_score": result.relevance_score,
                    "success": result.success
                })
            
            return {
                "success": True,
                "domain": response.domain,
                "successful_crawls": response.successful_crawls,
                "urls_considered": response.urls_considered,
                "results": results
            }
            
        except grpc.RpcError as e:
            logger.error(f"Domain crawl failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"gRPC error: {e.details()}"
            }
        except Exception as e:
            logger.error(f"Unexpected error in domain crawl: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # ===== Query Enhancement =====
    
    async def expand_query(
        self,
        query: str,
        num_variations: int = 3,
        user_id: str = "system",
        conversation_context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Expand query with variations
        
        Args:
            query: Original query
            num_variations: Number of variations to generate
            user_id: User ID
            conversation_context: Optional conversation context (last 2 messages) to help resolve vague references
            
        Returns:
            Dict with 'original_query', 'expanded_queries', 'key_entities', 'expansion_count'
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.QueryExpansionRequest(
                query=query,
                num_variations=num_variations,
                user_id=user_id
            )
            
            # Add conversation context if provided
            if conversation_context:
                request.conversation_context = conversation_context
            
            response = await self._stub.ExpandQuery(request)
            
            return {
                'original_query': response.original_query,
                'expanded_queries': list(response.expanded_queries),
                'key_entities': list(response.key_entities),
                'expansion_count': response.expansion_count
            }
            
        except grpc.RpcError as e:
            logger.error(f"Query expansion failed: {e.code()} - {e.details()}")
            return {
                'original_query': query,
                'expanded_queries': [query],
                'key_entities': [],
                'expansion_count': 1
            }
        except Exception as e:
            logger.error(f"Unexpected error in query expansion: {e}")
            return {
                'original_query': query,
                'expanded_queries': [query],
                'key_entities': [],
                'expansion_count': 1
            }
    
    # ===== Conversation Cache =====
    
    async def search_conversation_cache(
        self,
        query: str,
        conversation_id: str = None,
        freshness_hours: int = 24,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Search conversation cache for previous research
        
        Args:
            query: Search query
            conversation_id: Conversation ID (optional)
            freshness_hours: How recent to search (hours)
            user_id: User ID
            
        Returns:
            Dict with 'cache_hit' and 'entries'
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.CacheSearchRequest(
                query=query,
                conversation_id=conversation_id if conversation_id else "",
                freshness_hours=freshness_hours,
                user_id=user_id
            )
            
            response = await self._stub.SearchConversationCache(request)
            
            entries = []
            for entry in response.entries:
                entries.append({
                    'content': entry.content,
                    'timestamp': entry.timestamp,
                    'agent_name': entry.agent_name,
                    'relevance_score': entry.relevance_score
                })
            
            return {
                'cache_hit': response.cache_hit,
                'entries': entries
            }
            
        except grpc.RpcError as e:
            logger.error(f"Cache search failed: {e.code()} - {e.details()}")
            return {'cache_hit': False, 'entries': []}
        except Exception as e:
            logger.error(f"Unexpected error in cache search: {e}")
            return {'cache_hit': False, 'entries': []}
    
    # ===== Conversation Operations =====
    
    async def update_conversation_title(
        self,
        conversation_id: str,
        title: str,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Update conversation title
        
        Args:
            conversation_id: Conversation ID to update
            title: New title
            user_id: User ID (required - must match conversation owner)
        
        Returns:
            Dict with success, conversation_id, title, and message
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.UpdateConversationTitleRequest(
                user_id=user_id,
                conversation_id=conversation_id,
                title=title
            )
            
            response = await self._stub.UpdateConversationTitle(request)
            
            return {
                "success": response.success,
                "conversation_id": response.conversation_id,
                "title": response.title,
                "message": response.message,
                "error": response.error if hasattr(response, 'error') and response.error else None
            }
            
        except grpc.RpcError as e:
            logger.error(f"Update conversation title failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}",
                "message": "Failed to update conversation title"
            }
        except Exception as e:
            logger.error(f"Unexpected error updating conversation title: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to update conversation title"
            }
    
    # ===== Visualization Operations =====
    
    async def create_chart(
        self,
        chart_type: str,
        data: Dict[str, Any],
        title: str = "",
        x_label: str = "",
        y_label: str = "",
        interactive: bool = True,
        color_scheme: str = "plotly",
        width: int = 800,
        height: int = 600,
        include_static: bool = False
    ) -> Dict[str, Any]:
        """
        Create a chart or graph from structured data
        
        Args:
            chart_type: Type of chart (bar, line, pie, scatter, area, heatmap, box_plot, histogram)
            data: Chart data (format depends on chart type)
            title: Chart title (optional)
            x_label: X-axis label (optional)
            y_label: Y-axis label (optional)
            interactive: Generate interactive chart (default: True)
            color_scheme: Color scheme to use (default: "plotly")
            width: Chart width in pixels (default: 800)
            height: Chart height in pixels (default: 600)
            include_static: Also generate a static SVG version (default: False)
            
        Returns:
            Dict with success status, output format, and chart_data
        """
        try:
            await self._ensure_connected()
            
            # Serialize data to JSON
            data_json = json.dumps(data)
            
            request = tool_service_pb2.CreateChartRequest(
                chart_type=chart_type,
                data_json=data_json,
                title=title,
                x_label=x_label,
                y_label=y_label,
                interactive=interactive,
                color_scheme=color_scheme,
                width=width,
                height=height,
                include_static=include_static
            )
            
            response = await self._stub.CreateChart(request)
            
            if response.success:
                # Parse metadata JSON
                metadata = {}
                if response.metadata_json:
                    try:
                        metadata = json.loads(response.metadata_json)
                    except json.JSONDecodeError:
                        pass
                
                result = {
                    "success": True,
                    "chart_type": response.chart_type,
                    "output_format": response.output_format,
                    "chart_data": response.chart_data,
                    "metadata": metadata
                }

                if response.HasField("static_svg"):
                    result["static_svg"] = response.static_svg
                if response.HasField("static_format"):
                    result["static_format"] = response.static_format
                
                return result
            else:
                return {
                    "success": False,
                    "error": response.error if response.error else "Unknown error"
                }
            
        except grpc.RpcError as e:
            logger.error(f"Create chart failed: {e.code()} - {e.details()}")
            return {
                "success": False,
                "error": f"{e.code()}: {e.details()}"
            }
        except Exception as e:
            logger.error(f"Unexpected error creating chart: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # ===== File Analysis Operations =====
    
    async def analyze_text_content(
        self,
        content: str,
        include_advanced: bool = False,
        user_id: str = "system"
    ) -> Dict[str, Any]:
        """
        Analyze text content and return metrics
        
        Args:
            content: Text content to analyze
            include_advanced: If True, include advanced metrics (averages, etc.)
            user_id: User ID for logging
            
        Returns:
            Dict with text analysis metrics:
            - word_count: int
            - line_count: int
            - non_empty_line_count: int
            - character_count: int
            - character_count_no_spaces: int
            - paragraph_count: int
            - sentence_count: int
            - avg_words_per_sentence: float (if include_advanced)
            - avg_words_per_paragraph: float (if include_advanced)
        """
        try:
            await self._ensure_connected()
            
            request = tool_service_pb2.TextAnalysisRequest(
                content=content,
                include_advanced=include_advanced,
                user_id=user_id
            )
            
            response = await self._stub.AnalyzeTextContent(request)
            
            # Convert proto response to dict
            metrics = {
                "word_count": response.word_count,
                "line_count": response.line_count,
                "non_empty_line_count": response.non_empty_line_count,
                "character_count": response.character_count,
                "character_count_no_spaces": response.character_count_no_spaces,
                "paragraph_count": response.paragraph_count,
                "sentence_count": response.sentence_count,
            }
            
            # Add advanced metrics if requested
            if include_advanced:
                metrics["avg_words_per_sentence"] = response.avg_words_per_sentence
                metrics["avg_words_per_paragraph"] = response.avg_words_per_paragraph
            
            # Parse metadata JSON if present
            if response.metadata_json:
                try:
                    metadata = json.loads(response.metadata_json)
                    metrics["metadata"] = metadata
                except json.JSONDecodeError:
                    pass
            
            return metrics
            
        except grpc.RpcError as e:
            logger.error(f"Analyze text content failed: {e.code()} - {e.details()}")
            # Return empty metrics on error
            return {
                "word_count": 0,
                "line_count": 0,
                "non_empty_line_count": 0,
                "character_count": 0,
                "character_count_no_spaces": 0,
                "paragraph_count": 0,
                "sentence_count": 0,
                "error": f"{e.code()}: {e.details()}"
            }
        except Exception as e:
            logger.error(f"Unexpected error analyzing text content: {e}")
            return {
                "word_count": 0,
                "line_count": 0,
                "non_empty_line_count": 0,
                "character_count": 0,
                "character_count_no_spaces": 0,
                "paragraph_count": 0,
                "sentence_count": 0,
                "error": str(e)
            }


# Global client instance
_backend_tool_client: Optional[BackendToolClient] = None


async def get_backend_tool_client() -> BackendToolClient:
    """Get or create the global backend tool client"""
    global _backend_tool_client

    # Reuse existing connection - gRPC channels are designed to be long-lived
    if _backend_tool_client is None:
        _backend_tool_client = BackendToolClient()
        await _backend_tool_client.connect()
        logger.info(f"âœ… Backend tool client initialized and connected")

    return _backend_tool_client


async def close_backend_tool_client():
    """Close the global backend tool client"""
    global _backend_tool_client
    
    if _backend_tool_client:
        await _backend_tool_client.close()
        _backend_tool_client = None

