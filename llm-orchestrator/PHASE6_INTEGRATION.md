# Phase 6: Full Integration with Backend

**Status:** Ready for Testing

## What Was Done

### 1. Backend gRPC Client Proxy
Created `/opt/bastion/backend/api/grpc_orchestrator_proxy.py`:
- Connects to LLM Orchestrator on port 50051
- Streams responses in SSE format
- Health check endpoint
- Error handling with graceful fallback

### 2. Proto Files Synchronized
- Copied `orchestrator.proto` to `backend/protos/`
- Updated `backend/Dockerfile` to generate both proto files
- Backend can now act as gRPC client to orchestrator

### 3. Feature Flag Integration
- Modified `backend/api/async_orchestrator_api.py`
- Checks `use_grpc_orchestrator()` feature flag
- Routes to gRPC proxy when enabled
- Falls back to local orchestrator when disabled

### 4. Docker Compose Configuration
Added environment variables to backend service:
```yaml
- USE_GRPC_ORCHESTRATOR=true
- GRPC_ORCHESTRATOR_PERCENTAGE=100
```

### 5. Router Registration
- Registered `grpc_orchestrator_proxy` router in `backend/main.py`
- New endpoints:
  - `POST /api/async/orchestrator/grpc/stream`
  - `GET /api/async/orchestrator/grpc/health`

## How It Works

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USER REQUEST                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Backend: /api/async/orchestrator/stream         ‚îÇ
‚îÇ                   (async_orchestrator_api.py)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ  Feature Flag Check   ‚îÇ
                 ‚îÇ use_grpc_orchestrator ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                             ‚îÇ
              ‚ñº                             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  gRPC Proxy      ‚îÇ          ‚îÇ Local LangGraph ‚îÇ
    ‚îÇ  (Phase 5/6)     ‚îÇ          ‚îÇ  Orchestrator   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   LLM Orchestrator Microservice (port 50051)‚îÇ
    ‚îÇ   - FullResearchAgent                       ‚îÇ
    ‚îÇ   - Multi-round research                    ‚îÇ
    ‚îÇ   - Query expansion                         ‚îÇ
    ‚îÇ   - Gap analysis                            ‚îÇ
    ‚îÇ   - Web search integration                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Backend Tool Service (port 50052)          ‚îÇ
    ‚îÇ  - Document search                          ‚îÇ
    ‚îÇ  - Entity search                            ‚îÇ
    ‚îÇ  - Web search (SearxNG)                     ‚îÇ
    ‚îÇ  - Web crawling (Crawl4AI)                  ‚îÇ
    ‚îÇ  - Query expansion                          ‚îÇ
    ‚îÇ  - Conversation cache                       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Testing Instructions

### 1. Build and Start Services
```bash
cd /opt/bastion
docker compose up --build
```

### 2. Check Service Health

**LLM Orchestrator:**
```bash
curl http://localhost:8081/api/async/orchestrator/grpc/health
```

Expected response:
```json
{
  "status": "healthy",
  "details": {
    "phase": "Phase 5 Complete - Full Research Agent",
    "timestamp": "2025-11-10T..."
  }
}
```

**Backend Tool Service** (from within orchestrator):
```bash
cd /opt/bastion/llm-orchestrator
python test_phase3.py
```

### 3. Test Through Frontend

1. Open browser: `http://localhost:3001`
2. Start a new conversation
3. Ask a research question:
   - "What are the latest developments in quantum computing?"
   - "Research the history of the Panama Canal"
   - "Find information about climate change impacts on polar regions"

### 4. Monitor Logs

Watch for routing decision:
```bash
docker logs -f codex-dev-backend 2>&1 | grep "ROUTING TO gRPC"
```

Watch orchestrator processing:
```bash
docker logs -f codex-dev-llm-orchestrator
```

Watch tool service calls:
```bash
docker logs -f codex-dev-backend 2>&1 | grep "gRPC Tool Service"
```

## Feature Flag Control

### To Disable gRPC Orchestrator (Use Local)
Edit `docker-compose.yml`:
```yaml
- USE_GRPC_ORCHESTRATOR=false
```
Then rebuild:
```bash
docker compose up --build
```

### For Gradual Rollout (50% of traffic)
```yaml
- USE_GRPC_ORCHESTRATOR=true
- GRPC_ORCHESTRATOR_PERCENTAGE=50
```

### For Full Rollout (100% of traffic)
```yaml
- USE_GRPC_ORCHESTRATOR=true
- GRPC_ORCHESTRATOR_PERCENTAGE=100
```

## Expected Behavior

### With gRPC Orchestrator Enabled
1. User asks a question
2. Backend logs: `üéØ ROUTING TO gRPC ORCHESTRATOR (Phase 5)`
3. Request forwarded to llm-orchestrator:50051
4. FullResearchAgent processes:
   - Checks conversation cache
   - Performs local document search
   - Analyzes search quality
   - Identifies semantic gaps
   - Expands query if needed
   - Performs web search if needed
   - Synthesizes final response
5. Streams progress updates back through proxy
6. Final response displayed in frontend

### With gRPC Orchestrator Disabled
1. User asks a question
2. Backend logs: `üèõÔ∏è USING LOCAL ORCHESTRATOR (gRPC disabled)`
3. Uses existing `clean_research_agent.py`
4. Normal LangGraph workflow

## Troubleshooting

### "gRPC orchestrator not available - protos not generated"
- Backend Dockerfile failed to generate proto files
- Check build logs: `docker compose build backend`
- Verify `backend/protos/orchestrator.proto` exists

### "Connection refused to llm-orchestrator:50051"
- LLM Orchestrator service not running
- Check: `docker ps | grep llm-orchestrator`
- View logs: `docker logs codex-dev-llm-orchestrator`

### "gRPC health check failed"
- Orchestrator running but not responding
- Check health endpoint directly from backend container:
  ```bash
  docker exec codex-dev-backend python -c "import grpc; channel = grpc.insecure_channel('llm-orchestrator:50051'); print('Connected!')"
  ```

### Feature Flag Not Working
- Restart backend after changing environment:
  ```bash
  docker compose restart backend
  ```
- Verify environment variable loaded:
  ```bash
  docker exec codex-dev-backend env | grep GRPC
  ```

## Next Steps

1. **Test thoroughly** with various research queries
2. **Monitor performance** - compare response times
3. **Check error handling** - what happens when orchestrator fails?
4. **Validate citations** - are sources properly tracked?
5. **Test conversation continuity** - does context persist across messages?

## Success Criteria

- ‚úÖ Backend builds with orchestrator proto
- ‚úÖ Feature flag controls routing
- ‚úÖ gRPC proxy streams responses correctly
- ‚úÖ FullResearchAgent performs multi-round research
- ‚úÖ Tool callbacks work (orchestrator ‚Üí backend)
- ‚úÖ Error handling and fallback work
- ‚úÖ Conversation context maintained
- ‚úÖ Citations extracted and tracked

## Phase 7 Preview: Cleanup and Optimization

Once Phase 6 is validated:
1. Remove legacy `clean_research_agent.py` (after keeping as backup)
2. Optimize gRPC connection pooling
3. Add metrics and monitoring
4. Performance tuning for multi-round research
5. Citation extraction refinement
6. Entity detection integration
7. Tag detection for document organization

---

**By George! We're ready to test the new cavalry in action!**







